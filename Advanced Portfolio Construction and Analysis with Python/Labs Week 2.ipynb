{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Curse of Dimensionality\n",
    "\n",
    "To obtain efficient frontier of N Securities one must estimate:\n",
    "- **N** expected returns and **N** volaitily parameters\n",
    "- [N(N-1)/2] correlations\n",
    "\n",
    "Because we would be needing astronomical numbers as our **N** grows, we run into serious problem as we need a lot of data.\n",
    "\n",
    "To solve this issue we can apply few technics. \n",
    "- No Model Risk - High Sample Risk : Estimate the **The Sample Covariance Estimate**\n",
    "- Constant Correlation Model -> Assume that all the correlation parameters are identical.\n",
    "    \n",
    "        Cut the number [N(N-1)/2] of correlation parameters down to 1\n",
    "    \n",
    "        The optimal estimator of this constant correlation is the \"global\" average.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!!!!!! Dissertation !!!!!!\n",
    "# The Covariance Matrix with the Factor Model\n",
    "\n",
    "Simplest model is Sharpe's Single Factor Market Model\n",
    "- Regress the asset returns on the market. \n",
    "\n",
    "A single factor model isn't gonna do much so we should also add Explicit Factor Model, Macro Factors\n",
    "- Inflation\n",
    "- Interest Rates\n",
    "\n",
    "Another option is Micro Factors\n",
    "- Characteristics of the portfolio\n",
    "- Attributes of the stocks\n",
    "\n",
    "Implicit Factor Model, Statistical Factors\n",
    "- Statistical analyses\n",
    "\n",
    "Using a factor model is a convenient way to reduce the number of risk parameters. To estimate while introducing a reasonable amount of model risk.\n",
    "\n",
    "An implicit factor model is often preferred since it lets the data tell us what the relevant factors are thus alleviating model risk.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!!!!! Dissertation !!!!!\n",
    "# Shrinking the Covariance Matrix\n",
    "\n",
    "There is a paper called \"Honey I shrunk the Covariance Matrix(2004)\"\n",
    "\n",
    "We shrink the covariance matrix by taking the sample risk and the model risk together. Using both in a function to get our new Shrinked Covariance Matrix.\n",
    "\n",
    "The mixture of the sample risk and the model risk is proven to be better than having only to use one of them.\n",
    "\n",
    "Another paper \"Jagannathan and Ma(2003)\" that shows imposing constraints on weights is equivalent to perform statistical shrinkage.\n",
    "\n",
    "Statistical Shrinkage allows one to find the optimal trade-off between sample risk and model risk.\n",
    "\n",
    "It is based on an average of two covariance matrix estimates, one with high sample risk and one with high model risk."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Volatility\n",
    "\n",
    "Volatility varies over time.\n",
    "\n",
    "In this context using rolling windows is better than using expanding windows.\n",
    "\n",
    "In all cases,Historical Volatility Estimates are Backward Looking in nature they give an estimate for the average volatility over the sample period.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
